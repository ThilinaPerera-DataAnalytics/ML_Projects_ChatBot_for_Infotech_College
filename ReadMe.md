# ğŸ¤– Developing a ChatBot for InfoTech College of Business and IT


```
Individual Project 03
Machine Learning with Advanced Python
Infotech College of Business & IT
```
![alt text](cover_image.png)

A Retrieval-Augmented Generation (RAG) powered chatbot built for Infotech College
, enabling students and visitors to ask questions about courses, admissions, campus life, and more.

This project showcases practical use of **Large Language Models (LLMs)**, **Vector Databases**, and **Retrieval-Augmented Generation** to build a domain-specific assistant.

[![Demo Video](https://img.shields.io/badge/Demo-Video-blue)](https://drive.google.com/file/d/1cu-lLNyw4Zzq5NdTNp3v4W_iPnXPAHrT/view?usp=sharing)
[![Dataset](https://img.shields.io/badge/Dataset-GoogleDrive-orange)](https://drive.google.com/drive/folders/13zkRvYOpuv95XYIMl-vMVmHzPCEppjqF?usp=sharing)

---
## ğŸ“Œ Features

* âœ… **Document Processing**: Loads and splits college PDFs into retrievable knowledge chunks
* âœ… **Vector Search**: Embeddings stored in **ChromaDB** for fast retrieval
* âœ… **LLM Integration**: Powered by **Ollama** with **DeepSeek-r1 (1.5B)** model
* âœ… **RAG Pipeline**: Retrieval + Prompting + Context-aware responses
* âœ… **Interactive CLI**: Ask questions directly from terminal
* âœ… **Streamlit UI**: Simple front-end interface for users
* âœ… **Clean Responses**: Custom function strips unnecessary â€œthinkingâ€ text from LLM outputs

---
## ğŸ“‚ Project Structure

```
ML_Projects_ChatBot_for_Infotech_College/
â”‚â”€â”€ 1_data/                  # PDF documents (college info, about us, admissions, etc.)
|
â”‚â”€â”€ 2_src/
â”‚   â”œâ”€â”€ 1_chatbot/
â”‚   â”‚   â”œâ”€â”€ doc_load.py       # Load PDFs
â”‚   â”‚   â”œâ”€â”€ doc_split.py      # Split into chunks
â”‚   â”‚   â”œâ”€â”€ get_vectorstore.py # Create & save embeddings
â”‚   â”‚   â”œâ”€â”€ integrate_llm.py   # Connect to Ollama LLM
â”‚   â”‚   â”œâ”€â”€ build_rag.py       # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ clean.py           # Strip unwanted LLM text
â”‚   â”‚   â”œâ”€â”€ chat_interactive.py # CLI chatbot
â”‚   â”‚   â””â”€â”€ open_chatbot.py     # Final chatbot entrypoint
â”‚   â””â”€â”€ 2_frontend/
â”‚      â””â”€â”€ frontend.py        # Streamlit interface (optional)
â”‚
â”‚â”€â”€ .git/
â”‚â”€â”€ chromadb/
â”‚
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â””â”€â”€ cover_image.png
```

## ğŸ› ï¸ Tech Stack

* **Python 3.11**
* **LangChain** (RAG pipeline & integrations)
* **ChromaDB** (vector database)
* **Ollama** (local LLMs: DeepSeek-r1)
* **HuggingFace Sentence Transformers** (`all-MiniLM-L6-v2` for embeddings)
* **Streamlit** (UI)

---

## ğŸš€ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/ThilinaPerera-DataAnalytics/ML_Projects_ChatBot_for_Infotech_College.git
cd ML_Projects_ChatBot_for_Infotech_College
```

### 2. Create environment

```bash
conda create -n infochatbot python=3.11
conda activate infochatbot
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Setup Ollama & models

Install Ollama â†’ [ollama.com](https://ollama.com/)

```bash
ollama pull deepseek-r1:1.5b
```

### 5. Run pipeline scripts

```bash
# Load documents
python 2_src/1_chatbot/doc_load.py

# Split into chunks
python 2_src/1_chatbot/doc_split.py

# Create vectorstore
python 2_src/1_chatbot/get_vectorstore.py

# Run chatbot interactively
python 2_src/1_chatbot/chat_interactive.py
```

### 6. Run Streamlit UI

```bash
streamlit run 2_src/2_frontend/frontend.py
```

Then open: [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¡ Example Queries

**Q:** *How can I enroll at Infotech College?*
**A:** Visit [Enrollment Page](https://www.infotechcollege.com/enrollment/). Payment options include monthly installments, full payment, or smaller installment fees.

**Q:** *What courses are offered?*
**A:** Foundation in Information Technology (FIT) program, recognized by the University of Colombo School of Computing (UCSC), plus other IT-focused offerings.

**Q:** *Can I study medicine there?*
**A:** Infotech College specializes in IT & AI programs, not medicine.

---

## ğŸ“Š Performance

* **Mistral (7.3B)** â†’ \~200 sec response time (on Lenovo T530)
* **DeepSeek-r1 (1.5B)** â†’ \~60 sec response time (chosen for final chatbot)
* **Vector store size** â†’ 63 embeddings across 39 documents

---

## ğŸ¯ Key Learnings

* Practical application of **RAG pipelines** for domain-specific QA
* Trade-offs between **different LLM sizes** (speed vs detail)
* Building both **CLI** and **Web-based** chatbot interfaces

---

## ğŸ“Œ Next Steps




## ğŸ¤ Contributing

Contributions are welcome! Please fork the repo and submit a pull request with improvements.


## ğŸ‘¨â€ğŸ’» Author

**Thilina Perera**

    ğŸ“Œ Data Analytics Enthusiast | Machine Learning, Deep Learning, LLM/ LMM & NLP Explorer

ğŸ”— [LinkedIn](https://www.linkedin.com/in/thilina-perera-148aa934/) | [GitHub](https://github.com/ThilinaPerera-DataAnalytics)

---

## â­ Acknowledgement
    *



âœ¨ If you like this project, donâ€™t forget to **star â­ the repo**!




